2025 TODO:
    - Test the avoid tipping command logic (Down D-Pad on operator)
    - Test/Tune Swerve Rotation motor PID values (X button on driver)
        - Graph using Swerve tab 
            - /RBR/SwerveStates/Measured
              /RBR/SwerveStates/Setpoint
              /RBR/ChassisSpeed/Setpoint
            - and/or line charts in AdvantageScope
                - /RBR/Swerve/Rotation/Absolute/FL
                - /RBR/Swerve/Rotation/Absolute/FR
                - /RBR/Swerve/Rotation/Absolute/BL
                - /RBR/Swerve/Rotation/Absolute/BR
    - Test AprilTag readability from different starting points/angles on robot starting line
    - Test/verify distance accuracy from AprilTag pipeline output in photonvision UI
        - measure actual distance from lens to tag using measuring tape, compare to value output by UI
        - compare close vs. medium vs. far placement
    - Test LED Subsystem (L/R bumpers on driver)
    - Remove / re-set camera stream widget(s) in dashboards
    - Tune the CollisionDetector / Constants.Kinematics.COLLISION_THRESHOLD_DELTA_G value for tele-op
        - Graph /RBR/Gyro/Acceleration/X and /RBR/Gyro/Acceleration/Y values while driving
    - Create dashboard in Elastic with following widgets:
        - Gyro
        - Alerts
        - Field
        - Swerve 
        - Auto-chooser
        - Voltage view
        - Command Scheduler
        - Match Time
        - Total Current draw (text box or radial gauge)
    - Perform test driving runs to calculate std deviations for wheel odometry and vision for pose estimator (ensure finish pose has a AprilTag visible by vision)
        1. Drive straight a set distance, measure starting robot pose vs. finish robot pose
        2. Drive sideways (stafe straight) a set distance, measure starting robot pose vs. finish robot pose
        3. Drive diagonally a set distance, measure starting robot pose vs. finish robot pose
        - Repeat above several times, recording final measurements and comparing to each below
        - For each of the above, compare measured pose vs. reported pose from SwerveDriveOdometry (/RBR/PoseSwerveOdometry in AdvantageScope),
            this will give you odometry error value, use these errors to calculate std deviation
        - For each of the above, compare measured pose vs. reported pose from PhotonVision (/RBR/Vision/PoseEstimates/Accepted in AdvantageScope),
            this will give you vision error value, use these errors to calculate std deviation
----------
Done:
- Run SysId tests on drive motors on field
    - Re-run sysid tests using fresh battery (had to adjust voltage reading code, was returning 0 values)
        - Place robot with wheels all facing forward (bevels on left), ensure front of robot if facing correct direction
        - Deploy main robot code and start tele-op to reset the encoders (don't move the robot using joystick though)
        - Deploy sysid code, then run the 4 tests
        - Grab the .wpilog file from USB drive via SFTP to /U/ drive
    - Feed logs into SysId tool \FRC\2024\2024 WPILib Tools\SysId 2024
    - https://docs.wpilib.org/en/stable/docs/software/advanced-controls/system-identification/loading-data.html
    - https://docs.wpilib.org/en/stable/docs/software/advanced-controls/system-identification/analyzing-gains.html

Input:
    - Exposure and Gain:
        - Adjust these to achieve good brightness without flicker and low motion blur. This may vary based on lighting conditions in your competition environment
        - To avoid motion blur issues:
            - Lower your exposure as low as possible. Using gain and brightness to account for lack of brightness.
        - For all pipelines, exposure time should be set as low as possible while still allowing for the target to be reliably tracked. 
            This allows for faster processing as decreasing exposure will increase your camera FPS.
    - 1280x800 @100 FPS resolution
    - Mode: 3d
    - Exposure: 70.0
    - brightness: 0
    - Gain: 40
AprilTag:
    - Tag Family 36h11 (verify 2025 game is using the same family as 2024)
    - Decimate 2
    - Blur: 0
    - Threads: 4 (O PI has 8 cores/threads - so 4 per camera)
    - Refine Edges: On
    - Max Error Bits: 2 (maybe test with 3 at some point based on docs)
    - Decision Margin Cutoff: 30
    - Pose Iterations: 40
Output:
    - Show Multiple Targets: Off
    - Do Multi-Target Estimation: On (This is "Multi-Tag")

- Implement vision simulation
    - https://docs.photonvision.org/en/v2025.0.0-beta-4/docs/simulation/simulation-java.html
    - https://github.com/PhotonVision/photonvision/tree/2a6fa1b6ac81f239c59d724da5339f608897c510/photonlib-java-examples/swervedriveposeestsim

- For Krakens, TalonFX current limits:
    - Default values for 2025
        Stator current limit of 120 A
        Supply current limit of 70 A
        Supply current lower limit of 40 A after limiting (at 70 A) for 1 second
    - Example codebases:
        - https://github.com/StuyPulse/Izzi/blob/main/src/main/java/com/stuypulse/robot/subsystems/swerve/modules/KrakenSwerveModule.java
        - https://github.com/StuyPulse/Izzi/blob/main/src/main/java/com/stuypulse/robot/constants/Motors.java
